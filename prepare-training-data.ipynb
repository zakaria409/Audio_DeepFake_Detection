{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":591084,"sourceType":"datasetVersion","datasetId":287521},{"sourceId":3842332,"sourceType":"datasetVersion","datasetId":2286778},{"sourceId":5306083,"sourceType":"datasetVersion","datasetId":3084682},{"sourceId":6358196,"sourceType":"datasetVersion","datasetId":3579787}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport pandas as pd\nimport numpy as np\n\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.decomposition import PCA\n\n\nimport pickle\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:25:06.639950Z","iopub.execute_input":"2024-06-20T08:25:06.640337Z","iopub.status.idle":"2024-06-20T08:25:21.538431Z","shell.execute_reply.started":"2024-06-20T08:25:06.640297Z","shell.execute_reply":"2024-06-20T08:25:21.537485Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2024-06-20 08:25:10.231082: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-20 08:25:10.231237: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-20 08:25:10.368719: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"BASE_PATH = '../input/asvpoof-2019-dataset/LA/LA'\nFOLDS = 10\nSEED = 101\nDEBUG = True\n\n# Audio params\nSAMPLE_RATE = 16000\nDURATION = 5.0 # duration in second\nAUDIO_LEN = int(SAMPLE_RATE * DURATION)\n\n# Spectrogram params\nN_MELS = 128 # freq axis\nN_FFT = 2048\nSPEC_WIDTH = 256 # time axis\nHOP_LEN = AUDIO_LEN//(SPEC_WIDTH - 1) # non-overlap region\nFMAX = SAMPLE_RATE//2 # max frequency\nSPEC_SHAPE = [SPEC_WIDTH, N_MELS] # output spectrogram shape","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:25:21.539991Z","iopub.execute_input":"2024-06-20T08:25:21.540616Z","iopub.status.idle":"2024-06-20T08:25:21.546767Z","shell.execute_reply.started":"2024-06-20T08:25:21.540587Z","shell.execute_reply":"2024-06-20T08:25:21.545660Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Adding data from asvspoof-2019","metadata":{}},{"cell_type":"markdown","source":"# Meta Data\n\n* `speaker_id` : \t\tLA_****, a 4-digit speaker ID\n* `filename` : \tLA_****, name of the audio file\n* `system_id` : \t\tID of the speech spoofing system `(A01 - A19)`,  or, for **real** speech SYSTEM-ID is left blank ('-')\n* `class_name` : \t\t**bonafide** for genuine speech, or, **spoof** for fake/spoof speech\n* `target` : `1` for **fake/spoof**  and `0` for **real/genuine**","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(f'{BASE_PATH}/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt',\n                       sep=\" \", header=None)\ntrain_df.columns =['speaker_id','filename','system_id','null','class_name']\ntrain_df.drop(columns=['null'],inplace=True)\ntrain_df['filepath'] = f'{BASE_PATH}/ASVspoof2019_LA_train/flac/'+train_df.filename+'.flac'\ntrain_df['target'] = (train_df.class_name=='spoof').astype('int32') # set labels 1 for fake and 0 for real\nif DEBUG:\n    train_df = train_df.groupby(['target']).sample(2500).reset_index(drop=True)\nprint(f'Train Samples: {len(train_df)}')\n\n'''In actual train has around 22800 samples with 1 and 3000 around with 0'''\ntrain_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:25:21.548303Z","iopub.execute_input":"2024-06-20T08:25:21.548940Z","iopub.status.idle":"2024-06-20T08:25:21.693725Z","shell.execute_reply.started":"2024-06-20T08:25:21.548887Z","shell.execute_reply":"2024-06-20T08:25:21.692722Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Train Samples: 5000\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"  speaker_id      filename system_id class_name  \\\n0    LA_0091  LA_T_2424483         -   bonafide   \n1    LA_0085  LA_T_1691318         -   bonafide   \n\n                                            filepath  target  \n0  ../input/asvpoof-2019-dataset/LA/LA/ASVspoof20...       0  \n1  ../input/asvpoof-2019-dataset/LA/LA/ASVspoof20...       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>speaker_id</th>\n      <th>filename</th>\n      <th>system_id</th>\n      <th>class_name</th>\n      <th>filepath</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LA_0091</td>\n      <td>LA_T_2424483</td>\n      <td>-</td>\n      <td>bonafide</td>\n      <td>../input/asvpoof-2019-dataset/LA/LA/ASVspoof20...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LA_0085</td>\n      <td>LA_T_1691318</td>\n      <td>-</td>\n      <td>bonafide</td>\n      <td>../input/asvpoof-2019-dataset/LA/LA/ASVspoof20...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"count_target_1 = (train_df['target'] == 1).sum()\nprint(\"Number of rows with target variable as 1:\", count_target_1)\n# print(len(train_df)-22296)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:25:21.697251Z","iopub.execute_input":"2024-06-20T08:25:21.697778Z","iopub.status.idle":"2024-06-20T08:25:21.705394Z","shell.execute_reply.started":"2024-06-20T08:25:21.697734Z","shell.execute_reply":"2024-06-20T08:25:21.704184Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Number of rows with target variable as 1: 2500\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"valid_df = pd.read_csv(f'{BASE_PATH}/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt',\n                       sep=\" \", header=None)\nvalid_df.columns =['speaker_id','filename','system_id','null','class_name']\nvalid_df.drop(columns=['null'],inplace=True)\nvalid_df['filepath'] = f'{BASE_PATH}/ASVspoof2019_LA_dev/flac/'+valid_df.filename+'.flac'\nvalid_df['target'] = (valid_df.class_name=='spoof').astype('int32')\nif DEBUG:\n    valid_df = valid_df.groupby(['target']).sample(2000).reset_index(drop=True)\nprint(f'Valid Samples: {len(valid_df)}')\n\n\n'''In actual val has 22296 samples with 1 and 2548 with 0'''\nvalid_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:25:21.706705Z","iopub.execute_input":"2024-06-20T08:25:21.707049Z","iopub.status.idle":"2024-06-20T08:25:21.795454Z","shell.execute_reply.started":"2024-06-20T08:25:21.707020Z","shell.execute_reply":"2024-06-20T08:25:21.794384Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Valid Samples: 4000\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"  speaker_id      filename system_id class_name  \\\n0    LA_0070  LA_D_6289915         -   bonafide   \n1    LA_0099  LA_D_9253093         -   bonafide   \n\n                                            filepath  target  \n0  ../input/asvpoof-2019-dataset/LA/LA/ASVspoof20...       0  \n1  ../input/asvpoof-2019-dataset/LA/LA/ASVspoof20...       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>speaker_id</th>\n      <th>filename</th>\n      <th>system_id</th>\n      <th>class_name</th>\n      <th>filepath</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LA_0070</td>\n      <td>LA_D_6289915</td>\n      <td>-</td>\n      <td>bonafide</td>\n      <td>../input/asvpoof-2019-dataset/LA/LA/ASVspoof20...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LA_0099</td>\n      <td>LA_D_9253093</td>\n      <td>-</td>\n      <td>bonafide</td>\n      <td>../input/asvpoof-2019-dataset/LA/LA/ASVspoof20...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"test_df = pd.read_csv(f'{BASE_PATH}/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt',\n                       sep=\" \", header=None)\ntest_df.columns =['speaker_id','filename','system_id','null','class_name']\ntest_df.drop(columns=['null'],inplace=True)\ntest_df['filepath'] = f'{BASE_PATH}/ASVspoof2019_LA_eval/flac/'+test_df.filename+'.flac'\ntest_df['target'] = (test_df.class_name=='spoof').astype('int32')\nif DEBUG:\n    test_df = test_df.groupby(['target']).sample(3000).reset_index(drop=True)\nprint(f'Test Samples: {len(test_df)}')\n\n\n'''In actual test has 63882 samples with 1 and 7355 with 0'''\ntest_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:25:21.796718Z","iopub.execute_input":"2024-06-20T08:25:21.797023Z","iopub.status.idle":"2024-06-20T08:25:21.993485Z","shell.execute_reply.started":"2024-06-20T08:25:21.796999Z","shell.execute_reply":"2024-06-20T08:25:21.992163Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Test Samples: 6000\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"  speaker_id      filename system_id class_name  \\\n0    LA_0012  LA_E_5154555         -   bonafide   \n1    LA_0018  LA_E_1724045         -   bonafide   \n\n                                            filepath  target  \n0  ../input/asvpoof-2019-dataset/LA/LA/ASVspoof20...       0  \n1  ../input/asvpoof-2019-dataset/LA/LA/ASVspoof20...       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>speaker_id</th>\n      <th>filename</th>\n      <th>system_id</th>\n      <th>class_name</th>\n      <th>filepath</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LA_0012</td>\n      <td>LA_E_5154555</td>\n      <td>-</td>\n      <td>bonafide</td>\n      <td>../input/asvpoof-2019-dataset/LA/LA/ASVspoof20...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LA_0018</td>\n      <td>LA_E_1724045</td>\n      <td>-</td>\n      <td>bonafide</td>\n      <td>../input/asvpoof-2019-dataset/LA/LA/ASVspoof20...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"combined_df = pd.concat([train_df, valid_df, test_df])\ncombined_df.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:25:21.994778Z","iopub.execute_input":"2024-06-20T08:25:21.995127Z","iopub.status.idle":"2024-06-20T08:25:22.002570Z","shell.execute_reply.started":"2024-06-20T08:25:21.995089Z","shell.execute_reply":"2024-06-20T08:25:22.001475Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"combined_df.iloc[1].filepath","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:25:22.003814Z","iopub.execute_input":"2024-06-20T08:25:22.004154Z","iopub.status.idle":"2024-06-20T08:25:22.014782Z","shell.execute_reply.started":"2024-06-20T08:25:22.004126Z","shell.execute_reply":"2024-06-20T08:25:22.013713Z"},"trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'../input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_train/flac/LA_T_1691318.flac'"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"X = []\ny = []","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:25:22.016004Z","iopub.execute_input":"2024-06-20T08:25:22.016570Z","iopub.status.idle":"2024-06-20T08:25:22.022689Z","shell.execute_reply.started":"2024-06-20T08:25:22.016542Z","shell.execute_reply":"2024-06-20T08:25:22.021746Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"features = []\nlabels = []\nn_components = 40\nmax_length = 500","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:25:22.027423Z","iopub.execute_input":"2024-06-20T08:25:22.027768Z","iopub.status.idle":"2024-06-20T08:25:22.033939Z","shell.execute_reply.started":"2024-06-20T08:25:22.027741Z","shell.execute_reply":"2024-06-20T08:25:22.032832Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"for index, row in combined_df.iterrows():\n    filepath = row['filepath']  # Assuming 'filepath' is the column name\n    try:\n        audio, sr = sf.read(filepath)\n        \n        # Extract MFCC features\n        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n        \n        # Extract Mel-spectrogram features\n        melspec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=40)\n        melspec_db = librosa.power_to_db(melspec, ref=np.max)\n        \n        # Pad or trim the MFCC feature array to a fixed length\n        if mfccs.shape[1] < max_length:\n            mfccs = np.pad(mfccs, ((0, 0), (0, max_length - mfccs.shape[1])), mode='constant')\n        else:\n            mfccs = mfccs[:, :max_length]\n        \n        # Pad or trim the Mel-spectrogram feature array to a fixed length\n        if melspec_db.shape[1] < max_length:\n            melspec_db = np.pad(melspec_db, ((0, 0), (0, max_length - melspec_db.shape[1])), mode='constant')\n        else:\n            melspec_db = melspec_db[:, :max_length]\n        \n        # Perform feature fusion (concatenate MFCC and Mel-spectrogram features)\n        fused_features = np.concatenate((mfccs, melspec_db), axis=0)\n        \n        pca = PCA(n_components=n_components)\n        fused_features_pca = pca.fit_transform(fused_features.T)  # Transpose for PCA\n        fused_features_pca = fused_features_pca.T\n        features.append(fused_features_pca)\n\n        if row['target'] == 1:\n            labels.append(1)  # 1 for fake\n        else:\n            labels.append(0)  # 0 for real\n           \n    except Exception as e:\n        print(f\"Error encountered while parsing file: {filepath}\")\n        continue\n          \n        \n# X, y = np.array(features), np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:25:22.035239Z","iopub.execute_input":"2024-06-20T08:25:22.035550Z","iopub.status.idle":"2024-06-20T08:47:52.700036Z","shell.execute_reply.started":"2024-06-20T08:25:22.035523Z","shell.execute_reply":"2024-06-20T08:47:52.698509Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"X.extend(features)\ny.extend(labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:47:52.702796Z","iopub.execute_input":"2024-06-20T08:47:52.703931Z","iopub.status.idle":"2024-06-20T08:47:52.711519Z","shell.execute_reply.started":"2024-06-20T08:47:52.703878Z","shell.execute_reply":"2024-06-20T08:47:52.709939Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"\n## Adding data from deep-voice-deepfake-voice-recognition","metadata":{}},{"cell_type":"code","source":"import gc\n\ndel features\ndel labels\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:47:52.714296Z","iopub.execute_input":"2024-06-20T08:47:52.715555Z","iopub.status.idle":"2024-06-20T08:47:53.117004Z","shell.execute_reply.started":"2024-06-20T08:47:52.715507Z","shell.execute_reply":"2024-06-20T08:47:53.116014Z"},"trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"120016"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"features = []\nlabels = []","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:47:53.118623Z","iopub.execute_input":"2024-06-20T08:47:53.118959Z","iopub.status.idle":"2024-06-20T08:47:53.128267Z","shell.execute_reply.started":"2024-06-20T08:47:53.118932Z","shell.execute_reply":"2024-06-20T08:47:53.127322Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Segmenting the audio files into segments of 8 seconds\n\n# Reading fake audios, taking only 8 audios(since real has 8 only) and at a gap of 7 to include different variations\nfolder_path = \"/kaggle/input/deep-voice-deepfake-voice-recognition/KAGGLE/AUDIO/FAKE\"\n\ncount = 0\nfake_count = 0\nfor file in tqdm(os.listdir(folder_path)):\n    file_path = os.path.join(folder_path, file)\n    try:\n        \n        if(count==56):\n            break\n        count += 1\n        if(count%7!=0):\n            continue \n        print(count)\n        \n        # Load audio file\n        audio, _ = librosa.load(file_path, sr=16000)\n        n_samples = len(audio)\n        duration = 5\n        sample_rate = 16000\n        n_segments = int(np.ceil(n_samples / (sample_rate * duration)))\n        \n        for i in range(n_segments):\n            start = i * sample_rate * duration\n            end = min((i + 1) * sample_rate * duration, n_samples)\n            segment = audio[start:end]\n            \n            mfccs = librosa.feature.mfcc(y=segment, sr=16000, n_mfcc=40)\n            \n            melspec = librosa.feature.melspectrogram(y=segment, sr=16000, n_mels=40)\n            melspec_db = librosa.power_to_db(melspec, ref=np.max)\n            \n            # Pad or trim the feature array to a fixed length\n            if mfccs.shape[1] < max_length:\n                mfccs = np.pad(mfccs, ((0, 0), (0, max_length - mfccs.shape[1])), mode='constant')\n            else:\n                mfccs = mfccs[:, :max_length]\n                \n            # Pad or trim the Mel-spectrogram feature array to a fixed length\n            if melspec_db.shape[1] < max_length:\n                melspec_db = np.pad(melspec_db, ((0, 0), (0, max_length - melspec_db.shape[1])), mode='constant')\n            else:\n                melspec_db = melspec_db[:, :max_length]\n                         \n            fused_features = np.concatenate((mfccs, melspec_db), axis=0)\n            pca = PCA(n_components=n_components)\n            fused_features_pca = pca.fit_transform(fused_features.T)  # Transpose for PCA\n            fused_features_pca = fused_features_pca.T\n            fake_count+=1\n            features.append(fused_features_pca)\n            labels.append(1)  # 1 for fake\n\n    except Exception as e:\n        print(e)\n        print(f\"Error encountered while parsing file: {file_path}\")\n        continue\n\nprint(\"Number of fake audio segments:\", fake_count)  \n# print(labels)\n     \n","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:47:53.129562Z","iopub.execute_input":"2024-06-20T08:47:53.129933Z","iopub.status.idle":"2024-06-20T08:49:02.867648Z","shell.execute_reply.started":"2024-06-20T08:47:53.129898Z","shell.execute_reply":"2024-06-20T08:49:02.866337Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/56 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbed147dcdea4bceac78b5bd37fcac1e"}},"metadata":{}},{"name":"stdout","text":"7\n14\n21\n28\n35\n42\n49\n56\nNumber of fake audio segments: 747\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"count = 0\nreal_count = 0\n# Reading real audios\nfolder_path = \"/kaggle/input/deep-voice-deepfake-voice-recognition/KAGGLE/AUDIO/REAL\"\n\nfor file in tqdm(os.listdir(folder_path)):\n    file_path = os.path.join(folder_path, file)\n    try:\n        count+=1\n        print(count)\n        # Load audio file\n        audio, _ = librosa.load(file_path, sr=16000)\n        n_samples = len(audio)\n        duration = 5\n        sample_rate = 16000\n        n_segments = int(np.ceil(n_samples / (sample_rate * duration)))\n        \n        for i in range(n_segments):\n            start = i * sample_rate * duration\n            end = min((i + 1) * sample_rate * duration, n_samples)\n            segment = audio[start:end]\n            \n            mfccs = librosa.feature.mfcc(y=segment, sr=16000, n_mfcc=40)\n            \n            melspec = librosa.feature.melspectrogram(y=audio, sr=16000, n_mels=40)\n            melspec_db = librosa.power_to_db(melspec, ref=np.max)\n            # Pad or trim the feature array to a fixed length\n            if mfccs.shape[1] < max_length:\n                mfccs = np.pad(mfccs, ((0, 0), (0, max_length - mfccs.shape[1])), mode='constant')\n            else:\n                mfccs = mfccs[:, :max_length]\n            \n            if melspec_db.shape[1] < max_length:\n                melspec_db = np.pad(melspec_db, ((0, 0), (0, max_length - melspec_db.shape[1])), mode='constant')\n            else:\n                melspec_db = melspec_db[:, :max_length]\n            \n            \n            fused_features = np.concatenate((mfccs, melspec_db), axis=0)\n            pca = PCA(n_components=n_components)\n            fused_features_pca = pca.fit_transform(fused_features.T)  # Transpose for PCA\n            fused_features_pca = fused_features_pca.T\n\n            real_count+=1\n            features.append(fused_features_pca)\n            labels.append(0)  # 0 for real\n\n    except Exception as e:\n        print(f\"Error encountered while parsing file: {file_path}\")\n        continue\n                         \nprint(\"Number of real audio segments:\", real_count)  \n                         \n                         \n# X_deep_voice = np.array(features)\n# y_deep_voice = np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:49:02.870422Z","iopub.execute_input":"2024-06-20T08:49:02.872335Z","iopub.status.idle":"2024-06-20T08:57:23.986579Z","shell.execute_reply.started":"2024-06-20T08:49:02.872286Z","shell.execute_reply":"2024-06-20T08:57:23.985426Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8ebc6a7e72d45749de00b1eaa12eaa9"}},"metadata":{}},{"name":"stdout","text":"1\n2\n3\n4\n5\n6\n7\n8\nNumber of real audio segments: 755\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"X.extend(features)\ny.extend(labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:57:23.988798Z","iopub.execute_input":"2024-06-20T08:57:23.989231Z","iopub.status.idle":"2024-06-20T08:57:23.995203Z","shell.execute_reply.started":"2024-06-20T08:57:23.989192Z","shell.execute_reply":"2024-06-20T08:57:23.993822Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Adding data from wavefake","metadata":{}},{"cell_type":"code","source":"def read_data(folder_path, features, labels, count=500, fake=True):\n    number = 0\n    for file in tqdm(os.listdir(folder_path)):\n        file_path = os.path.join(folder_path, file)\n        try:\n            number+=1\n            if(number==count+1):\n                break\n            # Load audio file\n            audio, _ = librosa.load(file_path, sr=16000)\n\n            # Extract features (example: using Mel-Frequency Cepstral Coefficients)\n            mfccs = librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=40)\n\n            melspec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=40)\n            melspec_db = librosa.power_to_db(melspec, ref=np.max)\n            # Pad or trim the feature array to a fixed length\n            if mfccs.shape[1] < max_length:\n                mfccs = np.pad(mfccs, ((0, 0), (0, max_length - mfccs.shape[1])), mode='constant')\n            else:\n                mfccs = mfccs[:, :max_length]\n                \n            # Pad or trim the Mel-spectrogram feature array to a fixed length\n            if melspec_db.shape[1] < max_length:\n                melspec_db = np.pad(melspec_db, ((0, 0), (0, max_length - melspec_db.shape[1])), mode='constant')\n            else:\n                melspec_db = melspec_db[:, :max_length]\n                \n            fused_features = np.concatenate((mfccs, melspec_db), axis=0)\n            pca = PCA(n_components=n_components)\n            fused_features_pca = pca.fit_transform(fused_features.T)  # Transpose for PCA\n            fused_features_pca = fused_features_pca.T\n\n            features.append(fused_features_pca)\n\n            if fake == True:\n                labels.append(1)  # 1 for fake\n            else:\n                labels.append(0)  # 0 for real\n\n        except Exception as e:\n            print(f\"Error encountered while parsing file: {file_path}\")\n            continue","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:57:23.997587Z","iopub.execute_input":"2024-06-20T08:57:23.998105Z","iopub.status.idle":"2024-06-20T08:57:24.034331Z","shell.execute_reply.started":"2024-06-20T08:57:23.998045Z","shell.execute_reply":"2024-06-20T08:57:24.033047Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"del features\ndel labels\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:57:24.036590Z","iopub.execute_input":"2024-06-20T08:57:24.038219Z","iopub.status.idle":"2024-06-20T08:57:24.351025Z","shell.execute_reply.started":"2024-06-20T08:57:24.038161Z","shell.execute_reply":"2024-06-20T08:57:24.349855Z"},"trusted":true},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"38"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"features = []\nlabels = []","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:57:24.352411Z","iopub.execute_input":"2024-06-20T08:57:24.352741Z","iopub.status.idle":"2024-06-20T08:57:24.360440Z","shell.execute_reply.started":"2024-06-20T08:57:24.352713Z","shell.execute_reply":"2024-06-20T08:57:24.359427Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"folder_path = \"/kaggle/input/wavefake-test/generated_audio/common_voices_prompts_from_conformer_fastspeech2_pwg_ljspeech/generated\"\nread_data(folder_path, features, labels, 2000, True)\nprint(len(labels), len(features))\n\nfolder_path = \"/kaggle/input/wavefake-test/generated_audio/jsut_multi_band_melgan\"\nread_data(folder_path, features, labels, 2000, True)\nprint(len(labels), len(features))                         \n\nfolder_path = \"/kaggle/input/wavefake-test/generated_audio/jsut_parallel_wavegan\"\nread_data(folder_path, features, labels, 2000, True)\nprint(len(labels), len(features))\n\nfolder_path = \"/kaggle/input/wavefake-test/generated_audio/ljspeech_full_band_melgan\"\nread_data(folder_path, features, labels, 2000, True)\nprint(len(labels), len(features))                         \n\nfolder_path = \"/kaggle/input/wavefake-test/generated_audio/ljspeech_hifiGAN\"\nread_data(folder_path, features, labels, 2000, True)\nprint(len(labels), len(features))\n\nfolder_path = \"/kaggle/input/wavefake-test/generated_audio/ljspeech_melgan\"\nread_data(folder_path, features, labels, 2000, True)\nprint(len(labels), len(features))                         \n\nfolder_path = \"/kaggle/input/wavefake-test/generated_audio/ljspeech_melgan_large\"\nread_data(folder_path, features, labels, 2000, True)\nprint(len(labels), len(features))\n\nfolder_path = \"/kaggle/input/wavefake-test/generated_audio/ljspeech_multi_band_melgan\"\nread_data(folder_path, features, labels, 2000, True)\nprint(len(labels), len(features))                         \n\nfolder_path = \"/kaggle/input/wavefake-test/generated_audio/ljspeech_parallel_wavegan\"\nread_data(folder_path, features, labels, 2000, True)\nprint(len(labels), len(features))\n\nfolder_path = \"/kaggle/input/wavefake-test/generated_audio/ljspeech_waveglow\"\nread_data(folder_path, features, labels, 2000, True)\nprint(len(labels), len(features))                                              ","metadata":{"execution":{"iopub.status.busy":"2024-06-20T08:57:24.361946Z","iopub.execute_input":"2024-06-20T08:57:24.362389Z","iopub.status.idle":"2024-06-20T09:35:22.465699Z","shell.execute_reply.started":"2024-06-20T08:57:24.362351Z","shell.execute_reply":"2024-06-20T09:35:22.464441Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/16283 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae6baacfab97409b98e794daeb02fe9a"}},"metadata":{}},{"name":"stdout","text":"2000 2000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e834de7d87743af895e1969accc5bcf"}},"metadata":{}},{"name":"stdout","text":"4000 4000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2a1c7526d51480aaea10ffec93d2cb6"}},"metadata":{}},{"name":"stdout","text":"6000 6000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53e280211b9c42f983e4e825199d7d65"}},"metadata":{}},{"name":"stdout","text":"8000 8000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f74c3637a2d14adf96db8c78ba6dc3c1"}},"metadata":{}},{"name":"stdout","text":"10000 10000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a50fdee857c74f79a5331828276f004a"}},"metadata":{}},{"name":"stdout","text":"18000 18000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0b4ead8b8bb462f9208091ea2b0cfec"}},"metadata":{}},{"name":"stdout","text":"20000 20000\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"len(X)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:35:22.472009Z","iopub.execute_input":"2024-06-20T09:35:22.472860Z","iopub.status.idle":"2024-06-20T09:35:22.483407Z","shell.execute_reply.started":"2024-06-20T09:35:22.472807Z","shell.execute_reply":"2024-06-20T09:35:22.482195Z"},"trusted":true},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"16502"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"X.extend(features)\ny.extend(labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:35:22.485967Z","iopub.execute_input":"2024-06-20T09:35:22.487281Z","iopub.status.idle":"2024-06-20T09:35:22.499870Z","shell.execute_reply.started":"2024-06-20T09:35:22.487238Z","shell.execute_reply":"2024-06-20T09:35:22.498517Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"y.count(1)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:35:22.502069Z","iopub.execute_input":"2024-06-20T09:35:22.503087Z","iopub.status.idle":"2024-06-20T09:35:22.517161Z","shell.execute_reply.started":"2024-06-20T09:35:22.503029Z","shell.execute_reply":"2024-06-20T09:35:22.515601Z"},"trusted":true},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"28247"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"del features\ndel labels\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:35:22.520860Z","iopub.execute_input":"2024-06-20T09:35:22.522674Z","iopub.status.idle":"2024-06-20T09:35:22.825715Z","shell.execute_reply.started":"2024-06-20T09:35:22.522622Z","shell.execute_reply":"2024-06-20T09:35:22.824594Z"},"trusted":true},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"95"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"X = np.array(X)\ny = np.array(y)\nlen(y)-np.count_nonzero(y)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:35:22.827046Z","iopub.execute_input":"2024-06-20T09:35:22.827380Z","iopub.status.idle":"2024-06-20T09:35:24.561317Z","shell.execute_reply.started":"2024-06-20T09:35:22.827339Z","shell.execute_reply":"2024-06-20T09:35:24.560283Z"},"trusted":true},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"8255"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"if you are running into memory issues you can save the data as follows and so on. else, ignore next 3 cells","metadata":{}},{"cell_type":"code","source":"n = len(X)\nprint(\"len x:\",n)\nidx_25 = n // 4\nidx_50 = n // 2\nidx_75 = 3 * n // 4\n\nx_25 = X[:idx_25]\nx_50 = X[idx_25:idx_50]\nx_75 = X[idx_50:idx_75]\nx_100 = X[idx_75:]\nprint(\"sum len x:\",len(x_25)+len(x_50)+len(x_75)+len(x_100))\n\nny = len(y)\nprint(\"len y:\",n)\nidx_25 = n // 4\nidx_50 = n // 2\nidx_75 = 3 * n // 4\n\n# Slice the array into the desired ranges\ny_25 = y[:idx_25]\ny_50 = y[idx_25:idx_50]\ny_75 = y[idx_50:idx_75]\ny_100 = y[idx_75:]\nprint(\"sum len x:\",len(y_25)+len(y_50)+len(y_75)+len(y_100))","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:35:24.565860Z","iopub.execute_input":"2024-06-20T09:35:24.566249Z","iopub.status.idle":"2024-06-20T09:35:24.575289Z","shell.execute_reply.started":"2024-06-20T09:35:24.566220Z","shell.execute_reply":"2024-06-20T09:35:24.574265Z"},"trusted":true},"outputs":[{"name":"stdout","text":"len x: 36502\nsum len x: 36502\nlen y: 36502\nsum len x: 36502\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Save X\nwith open('X_fused1.pkl', 'wb') as f:\n    pickle.dump(x_25, f)\n\n# Save y\nwith open('y_fused1.pkl', 'wb') as f:\n    pickle.dump(y_25, f)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:35:24.576542Z","iopub.execute_input":"2024-06-20T09:35:24.576846Z","iopub.status.idle":"2024-06-20T09:35:27.117021Z","shell.execute_reply.started":"2024-06-20T09:35:24.576820Z","shell.execute_reply":"2024-06-20T09:35:27.116203Z"},"trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Save X\nwith open('X_fused2.pkl', 'wb') as f:\n    pickle.dump(x_50, f)\n\n# Save y\nwith open('y_fused2.pkl', 'wb') as f:\n    pickle.dump(y_50, f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save X\nwith open('X_fused.pkl', 'wb') as f:\n    pickle.dump(X, f)\n\n# Save y\nwith open('y_fused.pkl', 'wb') as f:\n    pickle.dump(y, f)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:45:17.582879Z","iopub.execute_input":"2024-06-20T09:45:17.583860Z","iopub.status.idle":"2024-06-20T09:45:40.919850Z","shell.execute_reply.started":"2024-06-20T09:45:17.583821Z","shell.execute_reply":"2024-06-20T09:45:40.918850Z"},"trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"os.remove(\"/kaggle/working/X_fused1.pkl\")","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:46:23.917856Z","iopub.execute_input":"2024-06-20T09:46:23.918272Z","iopub.status.idle":"2024-06-20T09:46:23.960276Z","shell.execute_reply.started":"2024-06-20T09:46:23.918238Z","shell.execute_reply":"2024-06-20T09:46:23.959444Z"},"trusted":true},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# Load X\nwith open('/kaggle/input/pickle-files/X_fused.pkl', 'rb') as f:\n    X = pickle.load(f)\n\n# Load y\nwith open('/kaggle/input/pickle-files/y_fused.pkl', 'rb') as f:\n    y = pickle.load(f)\n    \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}